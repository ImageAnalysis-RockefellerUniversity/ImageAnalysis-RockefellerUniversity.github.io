---
title: What Is an Image?
subtitle: Image capture, composition and basic analysis <br><br>Session 2 of the Fundamentals of Microscopy workshop 2026

author: <br>Ved Sharma, PhD
institute: <br>vsharma01@rockefeller.edu<br><br>Bio-Imaging Resource Center, The Rockefeller University
date: 2/26/2026
date-format: long

title-slide-attributes:
  data-visibility: "hidden"
#   data-background-image: "images/title_slide.png"


format:
  revealjs:
    margin: 0.05
    controls: true
    controls-layout: edges
    menu: 
      numbers: true
    width: 1280
    height: 720
    
    min-scale: 0.2
    max-scale: 2.0
    fig-cap-location: top
    footer: "Bio-Imaging Resource Center, The Rockefeller University"
    # theme: dark
    theme: styles_presentation.scss # defining css/scss as theme: and not as a css: is imp for correct html rendering (quarto render)
    slide-number: 'c'
    transition: slide
    background-transition: fade
    transition-speed: fast
    chalkboard: 
      buttons: true
    preview-links: auto
# resources:
#   - demo.pdf
---

## 
::: {.center-block}
<span class="line1">Fundamentals of Microscopy workshop - Session 2</span>
<!-- <span class="line1">Session 2</span> -->
<span class="line2">What Is an Image?</span>
<span class="line3">Image capture, composition and basic analysis</span><br>

<span class="line5">Ved Sharma, PhD</span><br>
<span class="line6">Advanced Image Analyst</span>
<span class="line6">Bio-Imaging Resource Center, The Rockefeller University</span>

![](images/Prostate_tissue_image/snapshot_crop_pixelation_transition.png)

:::

## Image Analysis @ Bio-Imaging Resource Center

::: {.absolute top="40%" left="40%" style="transform: translate(-40%, -40%); font-size: 1.2em; width: 100%; text-align: center;"}
[BIRC Image analysis website!](https://imageanalysis-rockefelleruniversity.github.io/){preview="true" style="padding: 15px 30px; background-color: #007bff; color: white; text-decoration: none; border-radius: 8px; font-size: 0.8em; font-weight: normal; box-shadow: 0 4px 6px rgba(0,0,0,0.1);"}  

::: {.smallerFont0}
<br>
https://imageanalysis-rockefelleruniversity.github.io/
:::
:::

## How are images formed in a microscope

:::{.smallerFont0 .absolute top="670" left="10"}
https://morgridge.org/feature/fluorescence-imaging-primer/
:::

::: {layout="[-5, 55, -10, 30]"}

::: {.img-overlay}
![](/Training/Fundamentals_of_microscopy/Presentation/images/fluorescence-illumination-highres.webp)
<div class="red-rectangle fragment"></div>

::: 
::: {.fragment}
![](images/IA_flowchart3.png)  
[Image Analysis workflow]{.smallerFont1 .underline}
:::
:::

::: {.hidden}
page 1 drawing from
/mnt/bircdata08/home-birc/BIRC/OMIBS Course Binder/08_16_2024_Friday/Luke Lavis/OMIBS_2024_Lavis_Lecture_1.pdf

noise, FFT, PSF: OMIBS_LaRiviere2024.pdf
PSF: PSF Quality OMIBS 2024 Turnbull v2.pdf
:::

## Outline 

:::{.smallerFont2 .custom_indent4}
### Part 1 - How cameras generate an image.

- camera types (CCD, CMOS)
- camera noise

### Part 2 - What is an image and how to work with it.

- bit depth
- metadata
- histogram
- display settings
- deconvolution vs AI-denoising
- image processing filters
:::

## Sensor vs Detector vs Camera {.custom_indent4}

::: {.fragment .smallerFont1}
### Sensor{.text-blue}
The fundamental element that converts a physical stimulus (light, heat, sound) into an electrical signal

  - A Passive Infrared (PIR) sensor detects body heat
  - the light-sensitive component that converts photons into electrical signals (e.g., CCD, CMOS)
:::

::: {.fragment .smallerFont1}
### Detector{.text-blue}
A broader term that includes sensors and other components to detect signal

- A motion detector may use PIR sensors to detect movement
- A heat detector uses temperature sensors to measure heat levels
- Camera is a type of detector which captures light to form images
:::

::: {.fragment .smallerFont1}
### Camera{.text-blue}
A complete imaging device that includes a detector along with optics, housing, and electronics for image capture and processing
:::

## Microscopy cameras {.custom_indent4}

::: {.smallerFont2}
### Color cameras{.text-blue}

- used for visual inspection  
- used for stains and dyes (histology)
    
<br>

### Monochrome cameras{.text-blue}  

- for fluorescence imaging  
- higher sensitivity than color cameras  
- used with emission filters to capture specific wavelength ranges  

:::

## Color camera - Bayer filter array (BFA) {.custom_indent2}

::: {.smallerFont1}
- Bayer filter array (BFA) is a color filter pattern to capture color information. 
- It consists of a grid of [red]{.text-red}, [green]{.text-green}, and [blue]{.text-blue} filters arranged in a specific pattern over the camera's sensor. 
- Each pixel on the sensor captures light filtered through one of these colored filters
- Interpolation of neighboring pixels generates a smooth representation of a colored field of view.
:::

::: {layout="[1,1,1]"}

![Bayer filter array](images/Bayer_pattern_on_sensor.svg.png)

![Bayer2](images/Bayer_pattern_on_sensor_profile.svg.png)

![Color interpolation](images/demosaic3.png)

:::

## Color camera - limitations {.custom_indent2}

::: {.smallerFont1}
- Each pixel effectively captures only 1/3 of incoming light, leading to reduced sensitivity compared to monochrome cameras
- The color information is not directly captured but rather inferred through interpolation, so cannot accurately extract the precise intensity values for further image analysis.
 
:::

## Monochrome camera {.custom_indent2}

::: {layout="[50,30]"}
::: {.smallerFont1}
- Each pixel captures the full intensity of incoming light, resulting in higher sensitivity and better signal-to-noise ratio (SNR) compared to color cameras.
- Monochrome cameras are [used for fluorescence imaging]{.text-blue} and quantitative analysis, as they provide more accurate intensity measurements without the need for interpolation.
- Monochrome cameras are used with emission filters to capture specific wavelength ranges, allowing for multi-channel imaging and analysis of different fluorophores.
- Monochrome cameras are also used in brightfield imaging for better contrast and resolution.
- Monochrome cameras are often used in scientific research and applications where accurate intensity measurements are critical, such as in cell biology, neuroscience, and materials science.
- Monochrome cameras can be used in combination with color filters or dichroic mirrors to capture multi-channel images for analysis of multiple fluorophores or stains in the same sample.
:::


::: {.element-center}
<br><br>
![](images/color-sensor-vs-monochrom-sensor-640w_v2.png)

:::

:::

## Microscopy cameras {.smallerFont1 visibility="hidden"}

- color cameras
  - Phone cameras
    - CCD
    - CMOS (reduced power consumption than CCD)
    - CMOS back-illuminated (use even less power than CMOS; higher price)
  - microscope color cameras
    - used for visual inspection
    - used for stains and dyes (histology)
    
- monochrome cameras
  - for fluorescence imaging
  - higher sensitivity than color cameras
  - used with emission filters to capture specific wavelength ranges

- Cameras – CCDs, EMCCDs and sCMOS;
- PMTs – newer GaAsP, Hybrid and SilVIR detectors ;
- Avalanche Photodiodes (APDs).

::: {.hidden}
Question for Behzad/Alison
1. termionology difference between sensor, detector and camera.
2. Phone color cameras vs microscope color cameras.

:::


## CCD vs EMCCD vs sCMOS
:::{.hidden}
https://camera.hamamatsu.com/jp/en/learn/technical_information/thechnical_guide/visual_guide.html
SilVIR detector:
https://evidentscientific.com/en/learn/white-papers/silvir-detector-system-for-the-fv4000-laser-confocal-microscope
:::

## Camera noise
- Read noise
- Dark noise
- Shot noise

## 
:::{.absolute top="50%" left="50%" style="transform: translate(-50%, -50%); font-size: 1.4em; width: 100%; color: blue; text-align: center;"}
Part 2<br>What is an image and how to analyze it.
:::

## Why should I learn about images and analysis in an era of AI and Deep Learning?

<br>

::: {.fragment}
![](images/AIDeBlur2.jpg){fig-align="center" width="80%"}

:::{.smallerFont0 .absolute top="670" left="20"}
https://forum.image.sc/
:::
:::

::: {.notes}
Hallucinations in AI image processing are common and can be very misleading. Understanding the basics of how images are formed and how they can be manipulated is crucial for interpreting results correctly and avoiding pitfalls in analysis.
:::


## Images as pixels {.smaller}

- Images are composed of a grid of pixels
- Each pixel contains intensity information

::: {layout="[1,1,1]"}
![Mouse embryonic fibroblast, F-actin](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18_pxInspect.png)

![Zoomed-in view](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18_zoom_pxInspect.png){.fragment}

![Image as a matrix of numbers (intensity values)](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18_zoom_pxInspect_table.png){.fragment}
:::

## Bit depth {.scrollable}

::: {layout="[44,-1,55]" .smallerFont1}
Number of bits (N) determine the range of intensity levels

|Image Type|Range of intensity levels (0 to 2^N^-1)|
|:---:|:---:|
|8-bit                 |0-255|
|16-bit                |0-4095|
|32-bit                |0-65,535|
|RGB color (3 x 8 bits)|0-255 per channel|
|||
:::


::: {.smallerFont1 .fragment}

|Bit depth (N)|# shades (2^N^)| Lookup table (LUT) |
|:---:|:---:|:---:|
|1  |2    | ![](images/shades_1bit.png)  |
|2  |4    | ![](images/shades_2bit.png)  |
|3  |8    | ![](images/shades_3bit.png)  |
|4  |16   | ![](images/shades_4bit.png)  |
|5  |32   | ![](images/shades_5bit.png)  |
|6  |64   | ![](images/shades_6bit.png)  |
|7  |128  | ![](images/shades_7bit.png)  |
|8  |256  | ![](images/shades_8bit.png)  |
  
<!-- ![Bit depth shades](images/bit_depth_shades.png) -->

:::

## Image display vs image analysis

#### Image display{.text-blue .fragment}

::: {.fragment .smallerFont2}
- Images are usually enhanced for better visualization (human eye) of features of interest
- qualitative assessment of the features of interest in the image
- typically figure panels for publications, presentations etc.
- Tools:
  - brightness/contrast
  - Lookup table (LUT)
  - Converting image (16/32 bit) to RGB
:::

## Image display vs image analysis
#### Image analysis{.text-blue}

::: {.smallerFont2}
- quantitative measurement of features of interest
  - Cell/nuclei counting, fluorescence intensity, shape etc.
- It's best to avoid any photo editing software (Photoshop, GIMP etc.)
- Any visual enhancement (pixel value change) is prohibited, except...
- Caveats: certain image enhancements are allowed:
  - image processing filters (e.g. Gaussian blur, median filter etc.). Original image must be used for intensity measurement.
  - deconvolution, de-noising
- make sure to apply the same image processing to all the images in a dataset, including controls and experimental groups, to avoid bias
:::

## 
:::{.absolute top="50%" left="50%" style="transform: translate(-50%, -50%); font-size: 1.2em; width: 100%; color: blue; text-align: center;"}
Can you tell which images are the [same]{.text-red} 

and which are [different]{.text-red}?
:::

--- 

<!-- ::: {layout="[[1,1,1], [1,1,1]]" layout-column-gap="0" layout-row-gap="0"} -->
<!-- ::: {layout-ncol="3" layout-nrow="2" layout-row-gap="0" layout-column-gap="0"} -->

::: {.tight-grid layout-ncol="3" layout-nrow="2" .element-center} 

![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1.png)

![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-2.png)

![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3.png)

![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-4.png)

![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-5.png)

![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-6.png)

:::

--- 

::: {.tight-grid layout-ncol="2" layout-nrow="1" .element-center}

::: {.img-stack}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1.png){.base-img}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1_BC.png){.overlay-img2 .fragment}
:::

::: {.img-stack}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3.png){.base-img}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3_BC.png){.overlay-img2 .fragment}
:::

:::

[Brightness and contrast settings are different for the two images, but the pixel values are identical.]{.smallerFont1 .fragment}

[Next: let's checkout the histograms of all 6 images. In Fiji, go to: `Analyze > Histogram` (or Press `H`)]{.smallerFont1 .fragment}


--- 

::: {.tight-grid layout-ncol="3" layout-nrow="2" .element-center}

::: {.img-stack}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1.png){.base-img}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1_histo_v2.png){.overlay-img .fragment}
:::

::: {.img-stack}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-2.png){.base-img}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-2_histo_v2.png){.overlay-img .fragment}
:::
::: {.img-stack}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3.png){.base-img}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3_histo_v2.png){.overlay-img .fragment}
:::
::: {.img-stack}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-4.png){.base-img}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-4_histo_v2.png){.overlay-img .fragment}
:::
::: {.img-stack}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-5.png){.base-img}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-5_histo_v2.png){.overlay-img .fragment}
:::
::: {.img-stack}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-6.png){.base-img}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-6_histo_v2.png){.overlay-img .fragment}
:::

:::

## Image display vs image analysis
<br>
Images that [look the same]{.text-red} may have [different]{.text-red} pixel values.

Images that [look different]{.text-red} may have [identical]{.text-red} pixel values.

<br>  

::: {.fragment}
When in doubt, check:

- Histogram
- Brightness and Contrast
- Lookup table (LUT)
:::

## Changing image bit-depth 
::: {.smaller}

#### Why would you want to change the bit-depth of an image?

- to save space (rarely)
- Because a particular plugin only works on 8/16/32-bit images (most common reason)
- so that a large image could be loaded into RAM/opened  and I can quickly take a look at it.   

::: {.fragment}
in Fiji, go to `Edit > Options > Conversions...`
:::

::: {layout="[-2, 20, -10, 30, 30]"}

::: {fig-cap-location="bottom" .smallerFont2 .fragment}
![](images/Fiji_Conversion_options_settings.png)

By default this setting is checked ON.
:::

![](images/bit_depth_change1.png){.fragment width="110%"}

![](images/bit_depth_change2.png){.fragment width="110%"}
:::

::: {.notes}
- there are many old imageJ plugins that only work on 8-bit images.
- If you process your images in Huygens (e.g. deconvolution), it first convert your images to 32 bit in the background
:::

:::

## Image Metadata {.smaller}

::: {layout="[-2, 55, 45]"}

::: {.img-overlay}
[Some metadata is displayed under the image title.]{.fragment}
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18.png)

:::{.smallerFont0 .absolute top="595" left="20"}
Mouse embryonic fibroblast stained with Phalloidin
:::

<div class="red-rectangle2 fragment"></div>

:::

::: {.fragment}
A bit more metadata could be found under:  
```Image > Properties```  
![](images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18_Properties_v2.png)  
:::

:::

## Test {visibility="hidden"}
testing...
```{r}
getwd()
list.files()
```

## Image Metadata (detailed) {.smaller}

::: {layout="[-15, 70, -15]"}
::: {.img-overlay}

```Plugins > Bio-Formats > Bio-Formats Importer```
![](images/Screenshot_Bio-Formats_Import_Options.png)
<div class="red-rectangle3 fragment"></div>

:::
:::

## Image Metadata (detailed) {.smaller .center-x}

metadata as key/value pairs  
![](images/Screenshot_metadata.png)

## Image Metadata (detailed) {.smaller .center-x}

<br>
metadata in OME-XML format
![](images/Screenshot_OME-XML_metadata.png)


## Signal-to-noise ratio (SNR) {.smaller .loose-lines}
- SNR is a measure of signal strength relative to background noise
- Higher SNR indicates clearer images with less noise
- SNR can be improved by optimizing imaging conditions, using better cameras, and applying image processing techniques

## Signal-to-background ratio (SBR) {.smaller .loose-lines}
- SBR is a measure of signal strength relative to background signal
- Higher SBR indicates better contrast between the object of interest and the background
- SBR can be improved by using specific stains, optimizing imaging conditions, and applying image processing techniques

## Noise reduction - Deonvolution vs AI-Denoising
:::{.hidden}

concept of deconvolution
https://zeiss-campus.magnet.fsu.edu/articles/basics/psf.html
:::

sample x psf = image

## File format

It is important to save images in a format that preserves the original pixel intensity values and metadata for accurate analysis.  
<br>
Common microscopy file formats: TIFF, OME-TIFF, CZI (Zeiss), ND2 (Nikon), LIF (Leica), etc.  
<br>
What is the difference between TIFF, PNG and JPEG?

What is compression and how it affects image quality and analysis?





## Resources {.smaller}

- [Principles of Scientific Imaging - imagej.net](https://imagej.net/imaging/principles#Pre-processing)
  - JPEG artifacts

Pete Bankhead book
https://petebankhead.gitbooks.io/imagej-intro/content/chapters/bit_depths/bit_depths.html


## {.custom_indent3}

Seminar slides and workshop material will be made available on our GitHub page:  
<br>
https://github.com/ImageAnalysis-RockefellerUniversity

::: {.notes}
Speaker notes go here.
:::

## Outline {.smaller .custom_indent2}

:::: {.columns}

::: {.column width="40%"}
- Segmentation
- Cell/particle Counting and Tracking
- Image denoising
:::

::: {.column width="60%" .fragment}
[Open-source Softwares]{.underline}  
ImageJ/Fiji, QuPath, Napari, CellProfiler, Icy  
<br>
[Commercial Softwares]{.underline}  
Imaris, Arivis, Aivia, Huygens, MetaMorph  
<br>
[Machine/Deep Learning frameworks]{.underline}  
Weka, ilastik, Labkit
StarDist, Cellpose, DeepImageJ, ZeroCostDL4Mic  
:::

::::

## What is a Raster Image?

::: {layout="[44,-1,55]" .smallerFont1}
- Raster images are composed of a grid of pixels
- Each pixel contains intensity information
- Number of bits (N) determine the range of intensity levels

|Image Type|Range of intensity levels (0 to 2^N^-1)|
|:---:|:---:|
|8-bit                 |0-255|
|16-bit                |0-4095|
|32-bit                |0-65,535|
|RGB color (3 x 8 bits)|0-255 per channel|
:::


::: {layout="[15,40,20,25]" .smallerFont2}
  
![Histogram](images/dew-maple-leaf-1974425_BCwindow.jpg)

<div class="img-overlay">
  ![8-bit image (256 shades)](images/dew-maple-leaf-1974425.jpg)
  <div class="red-square"></div>
</div>  

    
![Zoomed-in view](images/dew-maple-leaf-1974425_crop.jpg)

  
![Image as a matrix of numbers (0-255)](images/dew-maple-leaf-1974425_crop_text.jpg)
:::

## Segmentation {.smaller .loose-lines .custom_indent}

Identifying object(s) of interest in an image  
&emsp;- cells, nuclei, membrane, transcription sites etc.

Segmentation is usually followed by quantitative analysis of object(s)  
&emsp;- number of cells/nuclei, mean fluorescence intensity, shape etc.


Divide image into areas representing object(s) of interest and background  

::: {.fragment}
[Segmentation is not an easy task to solve in most practical cases]{.mark}  
&emsp;- Signal variability throughout the image  
&emsp;- Noise, blur and other distortions caused by the imperfect imaging conditions  
:::

## Segmentation tools {.smaller .loose-lines}
::: {.custom_indent}
- Global thresholding, local thresholding
- Image processing filters – Gaussian, Median, Sobel etc.
- Machine learning methods (supervised learning) - Weka, Labkit, ilastik 
- Deep Learning methods - StarDist, Cellpose
- 3D segmentation - Imaris, Arivis
:::

## Segmentation using global thresholding

::: {layout="[28, 40]"}
![Nuclei stained with Hoechst](images/AS_09125_050116000001_A24f00d0_slice2_channel1.png)

![Threshold 1](images/global_Thr2.png)
:::

::: {.smallerFont0 .absolute top="670" left="0"}
Human HT29 colon cancer cells,  Image from Broad Bioimage Benchmark Collection, Ljosa et al. 2012 Nat Methods
:::


## Segmentation using global thresholding {transition="none"}

::: {layout="[28, 40]"}
![Nuclei stained with Hoechst](images/AS_09125_050116000001_A24f00d0_slice2_channel1.png)

![Threshold 2](images/global_Thr1.png)
:::

::: {.smallerFont0 .absolute top="670" left="0"}
Human HT29 colon cancer cells,  Image from Broad Bioimage Benchmark Collection, Ljosa et al. 2012 Nat Methods
:::


## Segmentation with local thresholding

![Nuclei stained with Hoechst](images/AS_09125_050116000001_A24f00d0_slice2_channel1.png){.absolute top="40" left="0" width="400" height="400"}

:::{.smallerFont1 .absolute top="200" left="450"}
Auto Local <br>Threshold <br>in Fiji
:::

![](images/arrow.png){.absolute top="320" left="450" width="120" height="40"}

![](images/AS_09125_050116000001_A24f00d0_slice2_channel1_autoLocalThr.png){.absolute top="65" left="620" width="640" height="640"}

::: {.smallerFont0 .absolute top="600" left="0"}
Human HT29 colon cancer cells,  Image from Broad <br>Bioimage Benchmark Collection, Ljosa et al. 2012 Nat Methods
:::

## Segmentation using Machine Learning {.smaller .loose-lines .custom_indent2}
Supervised learning - pixel classification using Random Forest classifier

Fiji (Weka and Labkit plugins), ilastik, QuPath, Napari, CellProfiler

Requires orders of magnitude less training data/resources than Deep Learning methods

## {transition="none"}
![](images/labkit_1.png){fig-align="center"}

:::{.smallerFont3 .absolute top="692" left="74"}
Hoechst-stained Nuclei, image courtesy of Cherie Au, Giannakakou Lab, Weill Cornell Medicine
:::

## {transition="none"}
![](images/labkit_2.png){fig-align="center"}

:::{.smallerFont3 .absolute top="692" left="74"}
Hoechst-stained Nuclei, image courtesy of Cherie Au, Giannakakou Lab, Weill Cornell Medicine
:::

## {transition="none"}
![](images/labkit_3.png){fig-align="center"}

:::{.smallerFont3 .absolute top="692" left="74"}
Hoechst-stained Nuclei, image courtesy of Cherie Au, Giannakakou Lab, Weill Cornell Medicine
:::

## Segmentation using Deep Learning {.smallerFont1 .loose-lines}

:::: {.columns}
::: {.column width="2%"}
:::
::: {.column width="55%"}
Most accurate methods available for cells/nuclei segmentation  
[Step 1: Training]{.underline}  
Generating a Deep Learning model is resource hungry:  
- High-end workstation  
- Large amounts of training data (images and annotations)  
- Training could take hours to days  
- Good programming knowledge required - Python  

[Step 2: Prediction]{.underline}  
Using the model from step 1 to predict the segmentation results :  
- A regular laptop is just fine  
- Prediction takes seconds to mins  
- Little to no programming knowledge required  
:::
::: {.column width="2%"}
:::

::: {.column width="40%" .fragment}

<br>

![StarDist (2018)](images/stardist_paper_title.png)

<br>

![Cellpose (2021)](images/cellpose_paper_title.png)
:::
::::

## Segmentation using Deep Learning
<br>

::: {layout="[1,1,1]" .smallerFont2}
  
![Original](images/Hoechst-C42-ARv7_Dox.jpg)

![StarDist plugin in Fiji](images/Hoechst-C42-ARv7_Dox_Fiji_StarDist.png)
  
![Cellpose](images/Hoechst-C42-ARv7_Dox_cellpose.png)
:::
:::{.smallerFont0 .absolute top="610" left="0"}
Hoechst-stained Nuclei, image courtesy of Cherie Au, Giannakakou Lab, Weill Cornell Medicine
:::
:::{.smallerFont1 .absolute top="660" left="200"}
Workshop Exercise 1: StarDist based nuclear segmenation in a challenging image in Fiji
:::

## Segmentation using StarDist in Napari
![](images/Hoechst-C42-ARv7_Dox_Napari_StarDist.png){fig-align="center"}

## Segmentation using StarDist in Qupath
![](images/Hoechst-C42-ARv7_Dox_QuPath_StarDist.png){fig-align="center"}

## {.center}
::: {.r-fit-text}
[Segmentation – comparison of Deep Learning models]{style="color:#c00000;"}
:::

## {transition="none"}
![](images/Fig%203%20-%20cellpose%20paper_cellpose%20seg.png){fig-align="center"}

:::{.absolute top="20" left="50"}
[Cellpose]{style="color:#c00000; font-size:1.2em"}
:::

:::{.smallerFont0 .absolute top="650" left="1000"}
Stringer et al 2021, Nat Methods
:::

## {transition="none"}
![](images/Fig%20S4%20-%20cellpose%20paper_stardist%20seg.png){fig-align="center"}

:::{.absolute top="20" left="50"}
[StarDist]{style="color:#c00000; font-size:1.2em"}
:::

:::{.smallerFont0 .absolute top="650" left="1000"}
Stringer et al 2021, Nat Methods
:::

## {.center}
::: {.r-fit-text}
[&emsp;&emsp;&emsp;&emsp;Challenging cases&emsp;&emsp;&emsp;&emsp;]{style="color:#c00000;"}
:::

## 1. Cell crowding
<br>

::: {layout="[1,1]"}
![Original image](images/022_img.png)

![Cellpose segmentation](images/022_img_cp_masks_outlines.png){.fragment}
:::
:::{.smallerFont0 .absolute top="600" left="74"}
Image from https://github.com/MouseLand/cellpose
:::

## 2. Cell crowding + noisy signal
::: {layout="[1,1]"}
![Original image](images/020_img.png)

![Cellpose segmentation](images/020_img_cp_masks_outlines.png){.fragment}
:::
:::{.smallerFont0 .absolute top="650" left="74"}
Image from https://github.com/MouseLand/cellpose
:::

## 3. Cell crowding + uneven illumination
::: {layout="[1,1]"}
![Original image](images/053_img_grey.png)

![Cellpose segmentation](images/053_img_grey_cp_masks_outlines.png){.fragment}
:::
:::{.smallerFont0 .absolute top="710" left="25"}
Image from https://github.com/MouseLand/cellpose
:::