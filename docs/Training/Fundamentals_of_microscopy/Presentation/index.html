<!DOCTYPE html>
<html lang="en"><head>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-html/tabby.min.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.26">

  <meta name="author" content=" Ved Sharma, PhD">
  <meta name="dcterms.date" content="2026-02-26">
  <title>What Is an Image?</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../../../site_libs/revealjs/dist/theme/quarto-5b9c7bc364fbd947e42abad66de11387.css">
  <link href="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../../../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" data-visibility="hidden" class="quarto-title-block center">
  <h1 class="title">What Is an Image?</h1>
  <p class="subtitle">Image capture, composition and basic analysis <br><br>Session 2 of the Fundamentals of Microscopy workshop 2026</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
<br>Ved Sharma, PhD 
</div>
        <p class="quarto-title-affiliation">
            <br>vsharma01@rockefeller.edu<br><br>Bio-Imaging Resource Center, The Rockefeller University
          </p>
    </div>
</div>

  <p class="date">February 26, 2026</p>
</section>
<section id="section" class="slide level2">
<h2></h2>
<div class="center-block">
<p><span class="line1">Fundamentals of Microscopy workshop - Session 2</span> <!-- <span class="line1">Session 2</span> --> <span class="line2">What Is an Image?</span> <span class="line3">Image capture, composition and basic analysis</span><br></p>
<p><span class="line5">Ved Sharma, PhD</span><br> <span class="line6">Advanced Image Analyst</span> <span class="line6">Bio-Imaging Resource Center, The Rockefeller University</span></p>
<p><img data-src="images/Prostate_tissue_image/snapshot_crop_pixelation_transition.png"></p>
</div>
</section>
<section id="image-analysis-bio-imaging-resource-center" class="slide level2">
<h2>Image Analysis @ Bio-Imaging Resource Center</h2>
<div class="absolute" style="transform: translate(-40%, -40%); font-size: 1.2em; width: 100%; text-align: center;top: 40%; left: 40%; ">
<p><a href="https://imageanalysis-rockefelleruniversity.github.io/" data-preview="true" style="padding: 15px 30px; background-color: #007bff; color: white; text-decoration: none; border-radius: 8px; font-size: 0.8em; font-weight: normal; box-shadow: 0 4px 6px rgba(0,0,0,0.1);">BIRC Image analysis website!</a></p>
<div class="smallerFont0">
<p><br> https://imageanalysis-rockefelleruniversity.github.io/</p>
</div>
</div>
</section>
<section id="how-are-images-formed-in-a-microscope" class="slide level2">
<h2>How are images formed in a microscope</h2>
<div class="smallerFont0 absolute" style="top: 670px; left: 10px; ">
<p>https://morgridge.org/feature/fluorescence-imaging-primer/</p>
</div>
<div class="quarto-layout-panel" data-layout="[-5, 55, -10, 30]">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 5.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="img-overlay quarto-layout-cell" style="flex-basis: 55.0%;justify-content: flex-start;">
<img data-src="../../../Training/Fundamentals_of_microscopy/Presentation/images/fluorescence-illumination-highres.webp">
<div class="red-rectangle fragment">

</div>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 10.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="fragment quarto-layout-cell" style="flex-basis: 30.0%;justify-content: flex-start;">
<p><img data-src="images/IA_flowchart3.png"><br>
<span class="smallerFont1"><u>Image Analysis workflow</u></span></p>
</div>
</div>
</div>
<div class="hidden">
<p>page 1 drawing from /mnt/bircdata08/home-birc/BIRC/OMIBS Course Binder/08_16_2024_Friday/Luke Lavis/OMIBS_2024_Lavis_Lecture_1.pdf</p>
<p>noise, FFT, PSF: OMIBS_LaRiviere2024.pdf PSF: PSF Quality OMIBS 2024 Turnbull v2.pdf</p>
</div>
</section>
<section id="confocal-detectors" class="slide level2">
<h2>Confocal detectors</h2>
<p>Detectors can be cameras or confocal-style detectors such as:</p>
<ul>
<li>PMTs (photomultiplier tubes)</li>
<li>GaAsP</li>
<li>APDs (Avalanche Photodiodes)</li>
<li>SilVIR</li>
</ul>
<p>… will be discussed in session #4 on Confocal Microscopy</p>
</section>
<section id="outline" class="slide level2">
<h2>Outline</h2>
<div class="smallerFont2 custom_indent4">
<h3 id="part-1---how-cameras-generate-an-image.">Part 1 - How cameras generate an image.</h3>
<ul>
<li>camera types (CCD, EMCCD, CMOS)</li>
<li>camera noise</li>
</ul>
<h3 id="part-2---what-is-an-image-and-how-to-work-with-it.">Part 2 - What is an image and how to work with it.</h3>
<ul>
<li>bit depth</li>
<li>metadata</li>
<li>histogram</li>
<li>display settings</li>
<li>deconvolution vs AI-denoising</li>
<li>image processing filters</li>
</ul>
</div>
</section>
<section id="sensor-vs-detector-vs-camera" class="slide level2 custom_indent4">
<h2>Sensor vs Detector vs Camera</h2>
<div class="fragment smallerFont1">
<h3 class="text-blue" id="sensor">Sensor</h3>
<p>The fundamental element that converts a physical stimulus (light, heat, sound) into an electrical signal</p>
<ul>
<li>the light-sensitive component that converts photons into electrical signals (e.g., CCD, CMOS)</li>
</ul>
</div>
<div class="fragment smallerFont1">
<h3 class="text-blue" id="detector">Detector</h3>
<p>A broader term that includes sensors and other components to detect signal</p>
<ul>
<li>Camera is a type of detector which captures light to form images</li>
</ul>
</div>
<div class="fragment smallerFont1">
<h3 class="text-blue" id="camera">Camera</h3>
<p>A complete imaging device that includes a detector along with optics, housing, and electronics for image capture and processing</p>
</div>
</section>
<section id="microscopy-cameras" class="slide level2 custom_indent4">
<h2>Microscopy cameras</h2>
<div class="smallerFont2">
<h3 class="text-blue" id="color-cameras">Color cameras</h3>
<ul>
<li>used for visual inspection<br>
</li>
<li>used for stains and dyes (e.g.&nbsp;histology)</li>
</ul>
<p><br></p>
<h3 class="text-blue" id="monochrome-cameras">Monochrome cameras</h3>
<ul>
<li>for fluorescence imaging<br>
</li>
<li>higher sensitivity than color cameras<br>
</li>
<li>used with emission filters to capture specific wavelength ranges</li>
</ul>
</div>
</section>
<section id="color-camera---bayer-filter-array-bfa" class="slide level2 custom_indent2">
<h2>Color camera - Bayer filter array (BFA)</h2>
<div class="smallerFont1">
<ul>
<li>Bayer filter array (BFA) is a color filter pattern to capture color information.</li>
<li>It consists of a grid of <span class="text-red">red</span>, <span class="text-green">green</span>, and <span class="text-blue">blue</span> filters arranged in a specific pattern over the camera’s sensor.</li>
<li>Each pixel on the sensor captures light filtered through one of these colored filters</li>
<li>Interpolation of neighboring pixels generates a smooth representation of a colored field of view.</li>
</ul>
</div>
<div class="quarto-layout-panel" data-layout="[1,1,1]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Bayer filter array</figcaption>
<p><img data-src="images/Bayer_pattern_on_sensor.svg.png"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Mosaicing</figcaption>
<p><img data-src="images/Bayer_pattern_on_sensor_profile.svg.png"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Demosaicing: color interpolation</figcaption>
<p><img data-src="images/demosaic3.png"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="color-camera---limitations" class="slide level2 custom_indent2">
<h2>Color camera - limitations</h2>
<div class="smallerFont1">
<ul>
<li>Each pixel effectively captures only 1/3 of incoming light, leading to <span class="text-red">reduced sensitivity</span> compared to monochrome cameras</li>
<li>The color information is not directly captured but rather inferred through interpolation, so cannot accurately extract the precise intensity values for further image analysis.</li>
</ul>
</div>
</section>
<section id="monochrome-camera" class="slide level2 custom_indent2">
<h2>Monochrome camera</h2>
<div class="quarto-layout-panel" data-layout="[50,30]">
<div class="quarto-layout-row">
<div class="smallerFont1 quarto-layout-cell" style="flex-basis: 62.5%;justify-content: flex-start;">
<ul>
<li>Each pixel captures the full intensity of incoming light, resulting in <span class="text-red">higher sensitivity</span> and <span class="text-red">better signal-to-noise ratio (SNR)</span> compared to color cameras.</li>
<li>These cameras are <span class="text-red">used for fluorescence imaging</span> and <span class="text-red">quantitative analysis</span>, as they provide more accurate intensity measurements without the need for interpolation.</li>
<li>Used in combinations with dichroic mirrors and emission filters to capture specific wavelength ranges, allowing for <span class="text-red">multi-channel imaging</span> and analysis of different fluorophores.</li>
<li>Used in transmitted-light techniques for better contrast and resolution.</li>
<li>Used in scientific research and applications where accurate intensity measurements are critical, such as in cell biology, neuroscience, and materials science.</li>
</ul>
</div>
<div class="element-center quarto-layout-cell" style="flex-basis: 37.5%;justify-content: flex-start;">
<p><br><br> <img data-src="images/color-sensor-vs-monochrom-sensor-640w_v2.png"></p>
</div>
</div>
</div>
</section>

<section id="camera-types" class="slide level2 custom_indent2">
<h2>Camera types</h2>
<ul>
<li>CCD (Charge-Coupled Device)</li>
<li>EMCCD (Electron Multiplying CCD)</li>
<li>sCMOS (scientific Complementary Metal-Oxide-Semiconductor)</li>
</ul>
</section>
<section id="ccd-camera" class="slide level2 custom_indent2">
<h2>CCD camera</h2>
<div class="smallerFont0 absolute" style="top: 670px; left: 10px; ">
<p>from https://camera.hamamatsu.com</p>
</div>
<div class="quarto-layout-panel" data-layout="[50,30]">
<div class="quarto-layout-row">
<div class="smallerFont1 quarto-layout-cell" style="flex-basis: 62.5%;justify-content: flex-start;">
<ul>
<li>Each pixel of the CCD image sensor is composed of a photodiode and a potential well, which can be thought of as a bucket for photoelectrons.</li>
<li>This wavelength dependent conversion of light to photoelectrons is specified as the quantum efficiency (QE).</li>
<li>Photoelectrons accumulate in each bucket until it’s time for readout, when all of the photoelectrons are relayed from one bucket to the next down each row of pixels.</li>
<li>The charge is gathered pixel-by-pixel—serially—into a container at the end of the relay.</li>
<li>Once in the container, the photoelectrons are converted into voltage and processed into an image on the camera circuit board.</li>
<li>Because the photoelectrons are converted into signal (voltage) at a common port, the speed of image acquisition is limited.</li>
</ul>
</div>
<div class="element-center quarto-layout-cell" style="flex-basis: 37.5%;justify-content: flex-start;">
<p><br><br> <img data-src="images/CCD_image sensor2.jpeg"></p>
</div>
</div>
</div>
</section>
<section id="emccd-camera" class="slide level2 custom_indent2">
<h2>EMCCD camera</h2>
<div class="smallerFont0 absolute" style="top: 670px; left: 10px; ">
<p>https://www.teledynevisionsolutions.com</p>
</div>
<div class="quarto-layout-panel" data-layout="[50,30]">
<div class="quarto-layout-row">
<div class="smallerFont1 quarto-layout-cell" style="flex-basis: 62.5%;justify-content: flex-start;">
<ul>
<li>Similar to CCD except that they have an on-chip electron <span class="text-red">multiplication register</span> that amplifies the signal before readout, allowing for <span class="text-red">detection of very low light levels</span>.</li>
<li>Because the photoelectrons are converted into signal (voltage) at a common port, the speed of image acquisition is limited.</li>
</ul>
</div>
<div class="element-center quarto-layout-cell" style="flex-basis: 37.5%;justify-content: center;">
<p><img data-src="images/emccd_Teledyne.png"></p>
</div>
</div>
</div>
</section>
<section id="scmos-camera" class="slide level2 custom_indent2">
<h2>sCMOS camera</h2>
<div class="smallerFont0 absolute" style="top: 670px; left: 10px; ">
<p>https://camera.hamamatsu.com</p>
</div>
<div class="quarto-layout-panel" data-layout="[50,30]">
<div class="quarto-layout-row">
<div class="smallerFont1 quarto-layout-cell" style="flex-basis: 62.5%;justify-content: flex-start;">
<ul>
<li>In contrast with CCD and EMCCD sensors, each pixel of a CMOS image sensor is composed of a photodiode-amplifier pair.</li>
<li>Unlike a CCD sensor, photoelectrons are converted into voltage by each pixel’s photodiode-amplifier pair.</li>
<li>Because conversion to voltage happens in parallel instead of serially (CCD), image acquisition can be much faster for CMOS sensors.</li>
<li>scientific CMOS sensors combines high QE with fast frame rates and low noise, which translates into high speed, high-resolution biological images, even in low light situations.</li>
<li>For almost all applications, newer sCMOS cameras are a great choice, but for ultra-low light (single fluorescent molecules) EMCCDs may still be better.</li>
</ul>
</div>
<div class="element-center quarto-layout-cell" style="flex-basis: 37.5%;justify-content: flex-start;">
<p><br><br> <img data-src="images/CMOS_image sensor.jpeg"></p>
</div>
</div>
</div>
</section>

<section id="camera-noise" class="slide level2 custom_indent2">
<h2>Camera noise</h2>
<p>Random degradation of any image due to the inherent uncertainty of photon detection.</p>
<p><br> Mainly three types of noises in microscopy cameras:</p>
<div class="custom_indent4">
<ul>
<li>Shot noise</li>
<li>Dark noise</li>
<li>Read noise</li>
</ul>
</div>
</section>
<section id="shot-noise" class="slide level2 custom_indent2">
<h2>Shot noise</h2>
<div class="quarto-layout-panel" data-layout="[50,30]">
<div class="quarto-layout-row">
<div class="smallerFont1 quarto-layout-cell" style="flex-basis: 62.5%;justify-content: flex-start;">
<ul>
<li>Uncertainty in the arrival of photons</li>
<li>Arrival of any given photon is independent and cannot be precisely predicted</li>
<li>The probability of its arrival is governed by a Poisson distribution</li>
<li>It is most apparent at low signal levels, where the number of detected photons is small</li>
<li>Shot noise can be reduced by collecting more photons, either with longer exposure times or by combining multiple frames, but this may not always be feasible due to photobleaching or phototoxicity in live samples.</li>
</ul>
</div>
<div class="element-center quarto-layout-cell" style="flex-basis: 37.5%;justify-content: flex-start;">
<p><br> <img data-src="images/SS_detector.png"></p>
</div>
</div>
</div>
</section>
<section id="dark-noise" class="slide level2 custom_indent2">
<h2>Dark noise</h2>
<div class="quarto-layout-panel" data-layout="[50,30]">
<div class="quarto-layout-row">
<div class="smallerFont1 quarto-layout-cell" style="flex-basis: 62.5%;justify-content: flex-start;">
<ul>
<li>Uncertainty in the photon-to-electron conversion process.</li>
<li>Generated by thermal electrons in the camera sensor even in the absence of light.</li>
<li>Also governed by a Poisson distribution.</li>
<li>Becomes a problem for long exposure such as in bioluminescence imaging.</li>
<li>Temperature-dependent: can be reduced by cooling the camera sensor.</li>
</ul>
</div>
<div class="element-center quarto-layout-cell" style="flex-basis: 37.5%;justify-content: flex-start;">
<p><br><br> <img data-src="images/SS_detector.png"></p>
</div>
</div>
</div>
</section>
<section id="read-noise" class="slide level2 custom_indent2">
<h2>Read noise</h2>
<div class="smallerFont1 absolute" style="top: 620px; left: 5px; ">
<p><u>Resource</u><br>
https://andor.oxinst.com/learning/view/article/sensitivity-and-noise-of-ccd-emccd-and-scmos-sensors</p>
</div>
<div class="quarto-layout-panel" data-layout="[50,30]">
<div class="quarto-layout-row">
<div class="smallerFont1 quarto-layout-cell" style="flex-basis: 62.5%;justify-content: center;">
<ul>
<li>Uncertainty in the electronic readout process of the camera</li>
<li>Inherent to the process of converting CCD charge into a voltage signal and the subsequent analog-to-digital conversion</li>
<li>added uniformly to all pixels</li>
<li>Can be reduced by using a camera with low read noise specifications and optimizing the readout settings</li>
<li>Read noise is negligible in high signal applications</li>
<li>EMCCD: signal amplification happens before readout, so read noise is effectively reduced to near zero, making EMCCD ideal for low-light imaging.</li>
</ul>
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">CCD</th>
<th style="text-align: center;">EMCCD</th>
<th style="text-align: center;">sCMOS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Read noise</td>
<td style="text-align: center;">2-6 e<sup>-</sup></td>
<td style="text-align: center;">&lt;1 e<sup>-</sup></td>
<td style="text-align: center;">1-2 e<sup>-</sup></td>
</tr>
</tbody>
</table>
</div>
<div class="element-center quarto-layout-cell" style="flex-basis: 37.5%;justify-content: flex-start;">
<p><br><br> <img data-src="images/SS_detector.png"></p>
</div>
</div>
</div>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<div class="absolute" style="transform: translate(-50%, -50%); font-size: 1.4em; width: 100%; color: blue; text-align: center;top: 50%; left: 50%; ">
<p>Part 2<br>What is an image and how to analyze it.</p>
</div>
</section>
<section id="why-should-i-learn-about-images-and-analysis-in-an-era-of-ai-and-deep-learning" class="slide level2">
<h2>Why should I learn about images and analysis in an era of AI and Deep Learning?</h2>
<p><br></p>
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/AIDeBlur2.jpg" class="quarto-figure quarto-figure-center" style="width:80.0%"></p>
</figure>
</div>
<div class="smallerFont0 absolute" style="top: 670px; left: 20px; ">
<p>https://forum.image.sc/</p>
</div>
</div>
<aside class="notes">
<p>Hallucinations in AI image processing are common and can be very misleading. Understanding the basics of how images are formed and how they can be manipulated is crucial for interpreting results correctly and avoiding pitfalls in analysis.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="images-as-pixels" class="slide level2 smaller">
<h2>Images as pixels</h2>
<ul>
<li>Images are composed of a grid of pixels</li>
<li>Each pixel contains intensity information</li>
</ul>
<div class="quarto-layout-panel" data-layout="[1,1,1]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Mouse embryonic fibroblast, F-actin</figcaption>
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18_pxInspect.png"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Zoomed-in view</figcaption>
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18_zoom_pxInspect.png"></p>
</figure>
</div>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Image as a matrix of numbers (intensity values)</figcaption>
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18_zoom_pxInspect_table.png"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="bit-depth" class="slide level2 scrollable">
<h2>Bit depth</h2>
<div class="smallerFont0 quarto-layout-panel" data-layout="[44,-1,55]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 44.0%;justify-content: flex-start;">
<ul>
<li>Number of available grey levels used the represent the signal intensity<br>
</li>
<li>Determines how “finely” the signal is slices into discrete intensity levels</li>
<li>Number of bits (N) determine the range of intensity levels</li>
</ul>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 1.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 55.0%;justify-content: center;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;">Image Type</th>
<th style="text-align: center;">Range of intensity levels (0 to 2<sup>N</sup>-1)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">8-bit</td>
<td style="text-align: center;">0-255</td>
</tr>
<tr class="even">
<td style="text-align: center;">16-bit</td>
<td style="text-align: center;">0-4095</td>
</tr>
<tr class="odd">
<td style="text-align: center;">32-bit</td>
<td style="text-align: center;">0-65,535</td>
</tr>
<tr class="even">
<td style="text-align: center;">RGB color (3 x 8 bits)</td>
<td style="text-align: center;">0-255 per channel</td>
</tr>
<tr class="odd">
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="smallerFont1 fragment">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;">Bit depth (N)</th>
<th style="text-align: center;"># shades (2<sup>N</sup>)</th>
<th style="text-align: center;">Lookup table (LUT)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;"><img data-src="images/shades_1bit.png"></td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">4</td>
<td style="text-align: center;"><img data-src="images/shades_2bit.png"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;"><img data-src="images/shades_3bit.png"></td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;"><img data-src="images/shades_4bit.png"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;"><img data-src="images/shades_5bit.png"></td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;"><img data-src="images/shades_6bit.png"></td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">128</td>
<td style="text-align: center;"><img data-src="images/shades_7bit.png"></td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">256</td>
<td style="text-align: center;"><img data-src="images/shades_8bit.png"></td>
</tr>
</tbody>
</table>
<!-- ![Bit depth shades](images/bit_depth_shades.png) -->
</div>
</section>
<section id="dynamic-range-vs-bit-depth" class="slide level2">
<h2>Dynamic range vs bit depth</h2>
<div class="smallerFont0">
<p>Dynamic range is the ratio between the maximum and minimum signals that can be measured by the camera</p>
<p><span class="math display">\[\text{Dynamic Range} = \frac{\text{Full Well Capacity}}{\text{Read Noise}}\]</span></p>
<ul>
<li><span class="text-red">Full well capacity</span> is the maximum number of electrons a sensor can hold before saturation</li>
<li><span class="text-red">Read noise</span> is the minimum detectable signal above the noise floor</li>
</ul>
<p><u>Dynamic range</u> is about the sensor’s ability to capture extreme differences in light.<br>
<br> <u>Bit depth</u> is about the digital resolution used to display those differences.</p>
<p><br></p>
<h4 id="analogy">Analogy</h4>
<div class="custom_indent2">
<ul>
<li>Think of Dynamic Range as the total height of a staircase (from the floor to the ceiling).<br>
</li>
<li>Think of Bit Depth as the number of steps in that staircase.<br>
</li>
<li>A higher bit depth means more steps, making the transition from floor to ceiling smoother, but it doesn’t necessarily make the ceiling any higher.</li>
</ul>
</div>
<div class="smallerFont2 absolute fragment" style="top: 660px; left: 20px; ">
<p><u>Resources</u><br>
https://www.teledynevisionsolutions.com/learn/learning-center/imaging-fundamentals/bit-depth-full-well-and-dynamic-range/</p>
</div>
</div>
</section>
<section id="how-do-grey-intensity-values-relate-to-photons" class="slide level2">
<h2>How do grey intensity values relate to photons</h2>
<div class="smallerFont45 absolute fragment" style="top: 570px; left: 20px; ">
<p><u>Resources</u><br>
https://www.teledynevisionsolutions.com/learn/learning-center/imaging-fundamentals/camera-gain/<br>
https://www.teledynevisionsolutions.com/learn/learning-center/imaging-fundamentals/camera-sensitivity/<br>
https://www.azom.com/article.aspx?ArticleID=20215</p>
</div>
<div class="quarto-layout-panel" data-layout="[50,30]">
<div class="quarto-layout-row">
<div class="smallerFont1 quarto-layout-cell" style="flex-basis: 62.5%;justify-content: flex-start;">
<p>Intensity values/grey levels/Analog-to-Digital Units (ADU) are proportional to the number of photons detected by the camera sensor</p>
<ul>
<li>Convert grey levels to electrons <span class="math display">\[\text{Photoelectrons} = (\text{Grey levels} - \text{Offset}) \times \text{Gain}\]</span></li>
<li>Convert electrons to photons <span class="math display">\[\text{Photons} = \frac{\text{Photoelectrons}}{\text{QE}}\]</span></li>
</ul>
<p>need to know the <span class="text-red">camera offset, gain and quantum efficiency (QE)</span> of the camera sensor for the specific wavelength</p>
</div>
<div class="element-center quarto-layout-cell" style="flex-basis: 37.5%;justify-content: flex-start;">
<p><br> <img data-src="images/SS_detector2b.png"></p>
</div>
</div>
</div>
</section>
<section id="image-display-vs-image-analysis" class="slide level2">
<h2>Image display vs image analysis</h2>
<h4 class="text-blue fragment" id="image-display">Image display</h4>
<div class="fragment smallerFont2">
<ul>
<li>Images are usually enhanced for better visualization (human eye) of features of interest</li>
<li><span class="text-red">qualitative</span> assessment of the features of interest in the image</li>
<li>typically figure panels for publications, presentations etc.</li>
<li>Tools:
<ul>
<li>brightness/contrast</li>
<li>Lookup table (LUT)</li>
<li>Converting image (16/32 bit) to RGB</li>
</ul></li>
</ul>
</div>
</section>
<section id="image-display-vs-image-analysis-1" class="slide level2">
<h2>Image display vs image analysis</h2>
<h4 class="text-blue" id="image-analysis">Image analysis</h4>
<div class="smallerFont2">
<ul>
<li><span class="text-red">quantitative</span> measurement of features of interest
<ul>
<li>Cell/nuclei counting, fluorescence intensity, shape etc.</li>
</ul></li>
<li>It’s best to avoid any photo editing software (Photoshop, GIMP etc.)</li>
<li>Any visual enhancement (pixel value change) is prohibited, except…</li>
<li>Caveats: certain image enhancements are allowed:
<ul>
<li>image processing filters (e.g.&nbsp;Gaussian blur, median filter, gamma etc.). Original image must be used for intensity measurement.</li>
<li>deconvolution</li>
</ul></li>
<li>make sure to apply the same image processing to all the images in a dataset, including controls and experimental groups, to avoid bias</li>
<li>all this steps should be properly described in the methods section and/or fig legend of the paper.</li>
</ul>
</div>
</section>
<section id="section-2" class="slide level2">
<h2></h2>
<div class="absolute" style="transform: translate(-50%, -50%); font-size: 1.2em; width: 100%; color: blue; text-align: center;top: 50%; left: 50%; ">
<p>Can you tell which images are the <span class="text-red">same</span></p>
<p>and which are <span class="text-red">different</span>?</p>
</div>
</section>
<section class="slide level2">

<!-- ::: {layout="[[1,1,1], [1,1,1]]" layout-column-gap="0" layout-row-gap="0"} -->
<!-- ::: {layout-ncol="3" layout-nrow="2" layout-row-gap="0" layout-column-gap="0"} -->
<div class="tight-grid element-center quarto-layout-panel" data-layout-nrow="2" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1.png"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-2.png"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3.png"></p>
</div>
</div>
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-4.png"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-5.png"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-6.png"></p>
</div>
</div>
</div>
</section>
<section class="slide level2">

<div class="tight-grid element-center quarto-layout-panel" data-layout-nrow="1" data-layout-ncol="2">
<div class="quarto-layout-row">
<div class="img-stack quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1.png" class="base-img"> <img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1_BC.png" class="overlay-img2 fragment"></p>
</div>
<div class="img-stack quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3.png" class="base-img"> <img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3_BC.png" class="overlay-img2 fragment"></p>
</div>
</div>
</div>
<p><span class="smallerFont1 fragment">Brightness and contrast settings are different for the two images, but the pixel values are identical.</span></p>
<p><span class="smallerFont1 fragment">Next: let’s checkout the histograms of all 6 images. In Fiji, go to: <code>Analyze &gt; Histogram</code> (or Press <code>H</code>)</span></p>
</section>
<section class="slide level2">

<div class="tight-grid element-center quarto-layout-panel" data-layout-nrow="2" data-layout-ncol="3">
<div class="quarto-layout-row">
<div class="img-stack quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1.png" class="base-img"> <img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-1_histo_v2.png" class="overlay-img fragment"></p>
</div>
<div class="img-stack quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-2.png" class="base-img"> <img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-2_histo_v2.png" class="overlay-img fragment"></p>
</div>
<div class="img-stack quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3.png" class="base-img"> <img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-3_histo_v2.png" class="overlay-img fragment"></p>
</div>
</div>
<div class="quarto-layout-row">
<div class="img-stack quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-4.png" class="base-img"> <img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-4_histo_v2.png" class="overlay-img fragment"></p>
</div>
<div class="img-stack quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-5.png" class="base-img"> <img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-5_histo_v2.png" class="overlay-img fragment"></p>
</div>
<div class="img-stack quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<p><img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-6.png" class="base-img"> <img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF-6_histo_v2.png" class="overlay-img fragment"></p>
</div>
</div>
</div>
</section>
<section id="image-display-vs-image-analysis-2" class="slide level2">
<h2>Image display vs image analysis</h2>
<p><br> Images that <span class="text-red">look the same</span> may have <span class="text-red">different</span> pixel values.</p>
<p>Images that <span class="text-red">look different</span> may have <span class="text-red">identical</span> pixel values.</p>
<p><br></p>
<div class="fragment">
<p>When in doubt, check:</p>
<ul>
<li>Histogram</li>
<li>Brightness and Contrast</li>
<li>Lookup table (LUT)</li>
</ul>
</div>
</section>
<section id="changing-image-bit-depth" class="slide level2">
<h2>Changing image bit-depth</h2>
<section id="why-would-you-want-to-change-the-bit-depth-of-an-image" class="smaller">
<h4>Why would you want to change the bit-depth of an image?</h4>
<ul>
<li>to save space (rarely)</li>
<li>Because a particular ImageJ/Fiji plugin only works with 8/16/32-bit images (most common reason!)</li>
<li>so that a large image could be loaded into RAM/opened and I can quickly take a look at it.</li>
</ul>
<div class="fragment">
<p>in Fiji, go to <code>Edit &gt; Options &gt; Conversions...</code></p>
</div>
<div class="quarto-layout-panel" data-layout="[-2, 20, -10, 30, 30]">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 2.2%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="smallerFont2 fragment quarto-layout-cell" data-fig-cap-location="bottom" style="flex-basis: 21.7%;justify-content: center;">
<p><img data-src="images/Fiji_Conversion_options_settings.png"></p>
<p>By default this setting is checked ON.</p>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 10.9%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 32.6%;justify-content: center;">
<p><img data-src="images/bit_depth_change1.png" class="fragment"></p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 32.6%;justify-content: center;">
<p><img data-src="images/bit_depth_change2.png" class="fragment"></p>
</div>
</div>
</div>
<aside class="notes">
<ul>
<li>there are many old imageJ plugins that only work on 8-bit images.</li>
<li>If you process your images in Huygens (e.g.&nbsp;deconvolution), it first convert your images to 32 bit in the background</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
</section>
<section id="image-metadata" class="slide level2 smaller">
<h2>Image Metadata</h2>
<div class="quarto-layout-panel" data-layout="[-2, 55, 45]">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 2.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="img-overlay quarto-layout-cell" style="flex-basis: 53.9%;justify-content: flex-start;">
<p><span class="fragment">Some metadata is displayed under the image title.</span> <img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18.png"></p>
<div class="smallerFont0 absolute" style="top: 595px; left: 20px; ">
<p>Mouse embryonic fibroblast stained with Phalloidin</p>
</div>
<div class="red-rectangle2 fragment">

</div>
</div>
<div class="fragment quarto-layout-cell" style="flex-basis: 44.1%;justify-content: flex-start;">
<p>A bit more metadata could be found under:<br>
<code>Image &gt; Properties</code><br>
<img data-src="images/F-actin_phalloidin_MTLn3_MEF/SS_MEF_02_actin_z18_Properties_v2.png"></p>
</div>
</div>
</div>
</section>

<section id="image-metadata-detailed" class="slide level2 smaller">
<h2>Image Metadata (detailed)</h2>
<div class="quarto-layout-panel" data-layout="[-15, 70, -15]">
<div class="quarto-layout-row">
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 15.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="img-overlay quarto-layout-cell" style="flex-basis: 70.0%;justify-content: flex-start;">
<code>Plugins &gt; Bio-Formats &gt; Bio-Formats Importer</code> <img data-src="images/Screenshot_Bio-Formats_Import_Options.png">
<div class="red-rectangle3 fragment">

</div>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 15.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
</div>
</div>
</section>
<section id="image-metadata-detailed-1" class="slide level2 smaller center-x">
<h2>Image Metadata (detailed)</h2>
<p>metadata as key/value pairs<br>
<img data-src="images/Screenshot_metadata.png"></p>
</section>
<section id="image-metadata-detailed-2" class="slide level2 smaller center-x">
<h2>Image Metadata (detailed)</h2>
<p><br> metadata in OME-XML format <img data-src="images/Screenshot_OME-XML_metadata.png"></p>
</section>
<section id="signal-to-noise-ratio-snr" class="slide level2 smaller loose-lines">
<h2>Signal-to-noise ratio (SNR)</h2>
<ul>
<li>SNR is a measure of signal strength relative to background noise</li>
<li>Higher SNR indicates clearer images with less noise</li>
<li>SNR can be improved by optimizing imaging conditions, using better cameras, and applying image processing techniques</li>
</ul>
</section>
<section id="signal-to-background-ratio-sbr" class="slide level2 smaller loose-lines">
<h2>Signal-to-background ratio (SBR)</h2>
<ul>
<li>SBR is a measure of signal strength relative to background signal</li>
<li>Higher SBR indicates better contrast between the object of interest and the background</li>
<li>SBR can be improved by using specific stains, optimizing imaging conditions, and applying image processing techniques</li>
</ul>
</section>
<section id="noise-reduction---deonvolution-vs-ai-denoising" class="slide level2">
<h2>Noise reduction - Deonvolution vs AI-Denoising</h2>
<div class="hidden">
<p>concept of deconvolution https://zeiss-campus.magnet.fsu.edu/articles/basics/psf.html</p>
</div>
<p>sample x psf = image</p>
</section>
<section id="file-format" class="slide level2">
<h2>File format</h2>
<p>It is important to save images in a format that preserves the original pixel intensity values and metadata for accurate analysis.<br>
<br> Common microscopy file formats: TIFF, OME-TIFF, CZI (Zeiss), ND2 (Nikon), LIF (Leica), etc.<br>
<br> What is the difference between TIFF, PNG and JPEG?</p>
<p>What is compression and how it affects image quality and analysis?</p>
</section>
<section id="resources---camera-websites" class="slide level2">
<h2>Resources - camera websites</h2>

<img data-src="images/SS_camera_resources.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="acknowledgements" class="slide level2 custom_indent4">
<h2>Acknowledgements</h2>
<div class="smallerFont2">
<ul>
<li>Alison North</li>
<li>Tom Carroll</li>
<li>James Hudspeth</li>
</ul>
<p><br></p>
<ul>
<li>Tao Tong</li>
<li>Behzad Khajavi</li>
<li>Priyam Banerjee</li>
<li>Maria Belen Harreguy Alfonso</li>
<li>Ivan Rey Suarez</li>
</ul>
</div>
</section>
<section id="end" class="slide level2">
<h2>END</h2>
</section>
<section id="resources" class="slide level2 smaller">
<h2>Resources</h2>
<ul>
<li><a href="https://imagej.net/imaging/principles#Pre-processing">Principles of Scientific Imaging - imagej.net</a>
<ul>
<li>JPEG artifacts</li>
</ul></li>
</ul>
<p>Pete Bankhead book https://petebankhead.gitbooks.io/imagej-intro/content/chapters/bit_depths/bit_depths.html</p>
</section>
<section id="section-3" class="slide level2 custom_indent3">
<h2></h2>
<p>Seminar slides and workshop material will be made available on our GitHub page:<br>
<br> https://github.com/ImageAnalysis-RockefellerUniversity</p>
<aside class="notes">
<p>Speaker notes go here.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="outline-1" class="slide level2 smaller custom_indent2">
<h2>Outline</h2>
<div class="columns">
<div class="column" style="width:40%;">
<ul>
<li>Segmentation</li>
<li>Cell/particle Counting and Tracking</li>
<li>Image denoising</li>
</ul>
</div><div class="column fragment" style="width:60%;">
<p><u>Open-source Softwares</u><br>
ImageJ/Fiji, QuPath, Napari, CellProfiler, Icy<br>
<br> <u>Commercial Softwares</u><br>
Imaris, Arivis, Aivia, Huygens, MetaMorph<br>
<br> <u>Machine/Deep Learning frameworks</u><br>
Weka, ilastik, Labkit StarDist, Cellpose, DeepImageJ, ZeroCostDL4Mic</p>
</div></div>
</section>
<section id="what-is-a-raster-image" class="slide level2">
<h2>What is a Raster Image?</h2>
<div class="smallerFont1 quarto-layout-panel" data-layout="[44,-1,55]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 44.0%;justify-content: flex-start;">
<ul>
<li>Raster images are composed of a grid of pixels</li>
<li>Each pixel contains intensity information</li>
<li>Number of bits (N) determine the range of intensity levels</li>
</ul>
</div>
<div class="quarto-figure-spacer quarto-layout-cell" style="flex-basis: 1.0%;justify-content: flex-start;">
<p>&nbsp;</p>
</div>
<div class="quarto-layout-cell" style="flex-basis: 55.0%;justify-content: center;">
<table class="caption-top">
<thead>
<tr class="header">
<th style="text-align: center;">Image Type</th>
<th style="text-align: center;">Range of intensity levels (0 to 2<sup>N</sup>-1)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">8-bit</td>
<td style="text-align: center;">0-255</td>
</tr>
<tr class="even">
<td style="text-align: center;">16-bit</td>
<td style="text-align: center;">0-4095</td>
</tr>
<tr class="odd">
<td style="text-align: center;">32-bit</td>
<td style="text-align: center;">0-65,535</td>
</tr>
<tr class="even">
<td style="text-align: center;">RGB color (3 x 8 bits)</td>
<td style="text-align: center;">0-255 per channel</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="smallerFont2 quarto-layout-panel" data-layout="[15,40,20,25]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 15.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Histogram</figcaption>
<p><img data-src="images/dew-maple-leaf-1974425_BCwindow.jpg"></p>
</figure>
</div>
</div>
<div class="img-overlay quarto-layout-cell" style="flex-basis: 40.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>8-bit image (256 shades)</figcaption>
<p><img data-src="images/dew-maple-leaf-1974425.jpg"></p>
</figure>
</div>
<div class="red-square">

</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 20.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Zoomed-in view</figcaption>
<p><img data-src="images/dew-maple-leaf-1974425_crop.jpg"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 25.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Image as a matrix of numbers (0-255)</figcaption>
<p><img data-src="images/dew-maple-leaf-1974425_crop_text.jpg"></p>
</figure>
</div>
</div>
</div>
</div>
</section>
<section id="segmentation" class="slide level2 smaller loose-lines custom_indent">
<h2>Segmentation</h2>
<p>Identifying object(s) of interest in an image<br>
 - cells, nuclei, membrane, transcription sites etc.</p>
<p>Segmentation is usually followed by quantitative analysis of object(s)<br>
 - number of cells/nuclei, mean fluorescence intensity, shape etc.</p>
<p>Divide image into areas representing object(s) of interest and background</p>
<div class="fragment">
<p><mark>Segmentation is not an easy task to solve in most practical cases</mark><br>
 - Signal variability throughout the image<br>
 - Noise, blur and other distortions caused by the imperfect imaging conditions</p>
</div>
</section>
<section id="segmentation-tools" class="slide level2 smaller loose-lines">
<h2>Segmentation tools</h2>
<div class="custom_indent">
<ul>
<li>Global thresholding, local thresholding</li>
<li>Image processing filters – Gaussian, Median, Sobel etc.</li>
<li>Machine learning methods (supervised learning) - Weka, Labkit, ilastik</li>
<li>Deep Learning methods - StarDist, Cellpose</li>
<li>3D segmentation - Imaris, Arivis</li>
</ul>
</div>
</section>
<section id="segmentation-using-global-thresholding" class="slide level2">
<h2>Segmentation using global thresholding</h2>
<div class="quarto-layout-panel" data-layout="[28, 40]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 41.2%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Nuclei stained with Hoechst</figcaption>
<p><img data-src="images/AS_09125_050116000001_A24f00d0_slice2_channel1.png"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 58.8%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Threshold 1</figcaption>
<p><img data-src="images/global_Thr2.png"></p>
</figure>
</div>
</div>
</div>
</div>
<div class="smallerFont0 absolute" style="top: 670px; left: 0px; ">
<p>Human HT29 colon cancer cells, Image from Broad Bioimage Benchmark Collection, Ljosa et al.&nbsp;2012 Nat Methods</p>
</div>
</section>
<section id="segmentation-using-global-thresholding-1" class="slide level2" data-transition="none">
<h2>Segmentation using global thresholding</h2>
<div class="quarto-layout-panel" data-layout="[28, 40]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 41.2%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Nuclei stained with Hoechst</figcaption>
<p><img data-src="images/AS_09125_050116000001_A24f00d0_slice2_channel1.png"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 58.8%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Threshold 2</figcaption>
<p><img data-src="images/global_Thr1.png"></p>
</figure>
</div>
</div>
</div>
</div>
<div class="smallerFont0 absolute" style="top: 670px; left: 0px; ">
<p>Human HT29 colon cancer cells, Image from Broad Bioimage Benchmark Collection, Ljosa et al.&nbsp;2012 Nat Methods</p>
</div>
</section>
<section id="segmentation-with-local-thresholding" class="slide level2">
<h2>Segmentation with local thresholding</h2>
<div class="quarto-figure quarto-figure-center" style="top: 40px; left: 0px; width: 400px; height: 400px; ">
<figure>
<figcaption>Nuclei stained with Hoechst</figcaption>
<p><img data-src="images/AS_09125_050116000001_A24f00d0_slice2_channel1.png" class="absolute"></p>
</figure>
</div>
<div class="smallerFont1 absolute" style="top: 200px; left: 450px; ">
<p>Auto Local <br>Threshold <br>in Fiji</p>
</div>
<p><img data-src="images/arrow.png" class="absolute" style="top: 320px; left: 450px; width: 120px; height: 40px; "></p>
<p><img data-src="images/AS_09125_050116000001_A24f00d0_slice2_channel1_autoLocalThr.png" class="absolute" style="top: 65px; left: 620px; width: 640px; height: 640px; "></p>
<div class="smallerFont0 absolute" style="top: 600px; left: 0px; ">
<p>Human HT29 colon cancer cells, Image from Broad <br>Bioimage Benchmark Collection, Ljosa et al.&nbsp;2012 Nat Methods</p>
</div>
</section>
<section id="segmentation-using-machine-learning" class="slide level2 smaller loose-lines custom_indent2">
<h2>Segmentation using Machine Learning</h2>
<p>Supervised learning - pixel classification using Random Forest classifier</p>
<p>Fiji (Weka and Labkit plugins), ilastik, QuPath, Napari, CellProfiler</p>
<p>Requires orders of magnitude less training data/resources than Deep Learning methods</p>
</section>
<section id="section-4" class="slide level2" data-transition="none">
<h2></h2>

<img data-src="images/labkit_1.png" class="quarto-figure quarto-figure-center r-stretch"><div class="smallerFont3 absolute" style="top: 692px; left: 74px; ">
<p>Hoechst-stained Nuclei, image courtesy of Cherie Au, Giannakakou Lab, Weill Cornell Medicine</p>
</div>
</section>
<section id="section-5" class="slide level2" data-transition="none">
<h2></h2>

<img data-src="images/labkit_2.png" class="quarto-figure quarto-figure-center r-stretch"><div class="smallerFont3 absolute" style="top: 692px; left: 74px; ">
<p>Hoechst-stained Nuclei, image courtesy of Cherie Au, Giannakakou Lab, Weill Cornell Medicine</p>
</div>
</section>
<section id="section-6" class="slide level2" data-transition="none">
<h2></h2>

<img data-src="images/labkit_3.png" class="quarto-figure quarto-figure-center r-stretch"><div class="smallerFont3 absolute" style="top: 692px; left: 74px; ">
<p>Hoechst-stained Nuclei, image courtesy of Cherie Au, Giannakakou Lab, Weill Cornell Medicine</p>
</div>
</section>
<section id="segmentation-using-deep-learning" class="slide level2 smallerFont1 loose-lines">
<h2>Segmentation using Deep Learning</h2>
<div class="columns">
<div class="column" style="width:2%;">

</div><div class="column" style="width:55%;">
<p>Most accurate methods available for cells/nuclei segmentation<br>
<u>Step 1: Training</u><br>
Generating a Deep Learning model is resource hungry:<br>
- High-end workstation<br>
- Large amounts of training data (images and annotations)<br>
- Training could take hours to days<br>
- Good programming knowledge required - Python</p>
<p><u>Step 2: Prediction</u><br>
Using the model from step 1 to predict the segmentation results :<br>
- A regular laptop is just fine<br>
- Prediction takes seconds to mins<br>
- Little to no programming knowledge required</p>
</div><div class="column" style="width:2%;">

</div><div class="column fragment" style="width:40%;">
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>StarDist (2018)</figcaption>
<p><img data-src="images/stardist_paper_title.png"></p>
</figure>
</div>
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Cellpose (2021)</figcaption>
<p><img data-src="images/cellpose_paper_title.png"></p>
</figure>
</div>
</div></div>
</section>
<section id="segmentation-using-deep-learning-1" class="slide level2">
<h2>Segmentation using Deep Learning</h2>
<p><br></p>
<div class="smallerFont2 quarto-layout-panel" data-layout="[1,1,1]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Original</figcaption>
<p><img data-src="images/Hoechst-C42-ARv7_Dox.jpg"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>StarDist plugin in Fiji</figcaption>
<p><img data-src="images/Hoechst-C42-ARv7_Dox_Fiji_StarDist.png"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Cellpose</figcaption>
<p><img data-src="images/Hoechst-C42-ARv7_Dox_cellpose.png"></p>
</figure>
</div>
</div>
</div>
</div>
<div class="smallerFont0 absolute" style="top: 610px; left: 0px; ">
<p>Hoechst-stained Nuclei, image courtesy of Cherie Au, Giannakakou Lab, Weill Cornell Medicine</p>
</div>
<div class="smallerFont1 absolute" style="top: 660px; left: 200px; ">
<p>Workshop Exercise 1: StarDist based nuclear segmenation in a challenging image in Fiji</p>
</div>
</section>
<section id="segmentation-using-stardist-in-napari" class="slide level2">
<h2>Segmentation using StarDist in Napari</h2>

<img data-src="images/Hoechst-C42-ARv7_Dox_Napari_StarDist.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="segmentation-using-stardist-in-qupath" class="slide level2">
<h2>Segmentation using StarDist in Qupath</h2>

<img data-src="images/Hoechst-C42-ARv7_Dox_QuPath_StarDist.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="section-7" class="slide level2 center">
<h2></h2>
<div class="r-fit-text">
<p><span style="color:#c00000;">Segmentation – comparison of Deep Learning models</span></p>
</div>
</section>
<section id="section-8" class="slide level2" data-transition="none">
<h2></h2>

<img data-src="images/Fig 3 - cellpose paper_cellpose seg.png" class="quarto-figure quarto-figure-center r-stretch"><div class="absolute" style="top: 20px; left: 50px; ">
<p><span style="color:#c00000; font-size:1.2em">Cellpose</span></p>
</div>
<div class="smallerFont0 absolute" style="top: 650px; left: 1000px; ">
<p>Stringer et al 2021, Nat Methods</p>
</div>
</section>
<section id="section-9" class="slide level2" data-transition="none">
<h2></h2>

<img data-src="images/Fig S4 - cellpose paper_stardist seg.png" class="quarto-figure quarto-figure-center r-stretch"><div class="absolute" style="top: 20px; left: 50px; ">
<p><span style="color:#c00000; font-size:1.2em">StarDist</span></p>
</div>
<div class="smallerFont0 absolute" style="top: 650px; left: 1000px; ">
<p>Stringer et al 2021, Nat Methods</p>
</div>
</section>
<section id="section-10" class="slide level2 center">
<h2></h2>
<div class="r-fit-text">
<p><span style="color:#c00000;">    Challenging cases    </span></p>
</div>
</section>
<section id="cell-crowding" class="slide level2">
<h2>1. Cell crowding</h2>
<p><br></p>
<div class="quarto-layout-panel" data-layout="[1,1]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Original image</figcaption>
<p><img data-src="images/022_img.png"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Cellpose segmentation</figcaption>
<p><img data-src="images/022_img_cp_masks_outlines.png"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<div class="smallerFont0 absolute" style="top: 600px; left: 74px; ">
<p>Image from https://github.com/MouseLand/cellpose</p>
</div>
</section>
<section id="cell-crowding-noisy-signal" class="slide level2">
<h2>2. Cell crowding + noisy signal</h2>
<div class="quarto-layout-panel" data-layout="[1,1]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Original image</figcaption>
<p><img data-src="images/020_img.png"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Cellpose segmentation</figcaption>
<p><img data-src="images/020_img_cp_masks_outlines.png"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<div class="smallerFont0 absolute" style="top: 650px; left: 74px; ">
<p>Image from https://github.com/MouseLand/cellpose</p>
</div>
</section>
<section id="cell-crowding-uneven-illumination" class="slide level2">
<h2>3. Cell crowding + uneven illumination</h2>
<div class="quarto-layout-panel" data-layout="[1,1]">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Original image</figcaption>
<p><img data-src="images/053_img_grey.png"></p>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: flex-start;">
<div class="fragment">
<div class="quarto-figure quarto-figure-center">
<figure>
<figcaption>Cellpose segmentation</figcaption>
<p><img data-src="images/053_img_grey_cp_masks_outlines.png"></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<div class="smallerFont0 absolute" style="top: 710px; left: 25px; ">
<p>Image from https://github.com/MouseLand/cellpose</p>
</div>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">
<p>Bio-Imaging Resource Center, The Rockefeller University</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../../../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../../../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../../../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../../../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../../../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../../../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../../../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../../../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../../../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': true,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true,"numbers":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'slide',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'fast',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'fade',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1280,

        height: 720,

        // Factor of the display size that should remain empty around the content
        margin: 5.0e-2,

        // Bounds for smallest/largest possible scale to apply to content
        minScale: 0.2,

        maxScale: 2,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>