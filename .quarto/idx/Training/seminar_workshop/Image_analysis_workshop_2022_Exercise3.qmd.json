{"title":"Exercise 3 - Denoising using deep learning method (Noise2Void)","markdown":{"yaml":{"title":"Exercise 3 - Denoising using deep learning method (Noise2Void)"},"containsRefs":false,"markdown":"\n\n::: {layout-nrow=1 layout-ncol=2}\n![Original](PNGs/fish4_celegans_dyn-10_ceff-90_final.ics.ome_Z45.png)\n\n![After processing with trained Noise2Void model](PNGs/fish4_celegans_dyn-10_ceff-90_final.ics.ome_n2v_Z45.png)\n:::\n\nSpinning disk confocal image of FISH in C. elegans (image courtesy of [ABRF/LMRG Image Analysis Study](https://sites.google.com/view/lmrg-image-analysis-study)).  \n\n[Download TIF file](images/fish4_celegans.tif)  \n  \n- Open the above Z-stack in Fiji and run the command: \n  `Plugins › CSBDeep › N2V › N2V train + predict`  \n- You will be presented with a `N2V train + predict` window. Choose the following options and click OK.\n  - Axes of prediction input: XYZ\n  - Number of epochs: 10\n  - Number of steps per epoch: 10\n  - Batch size per step: 64\n  - Patch shape: 64\n  - Neighborhood readius: 5\n\n- A window showing the progress of different steps (Preparation, Training and Prediction) will open. As the training progresses, training loss (red) and validation loss (blue) curves are displayed in the window (see below). If training goes well, then both the red and blue curves will decrease with more cycles (epochs) of training and stabilize around a minimum loss value (~ 1.0 in the image below). Training loss goes down from the beginning but Validation loss (blue curve) usually goes up in the beginning and then comes down and approaches the red curve.\n\n  ![Training deep learning model](PNGs/N2V_training_progress.png)\n \n  If by the end of the training, red and blue curves do not stabilize to a minimum loss value, then increase the number of epochs to 20 or 30 and then run the command `N2V train + predict` again.\n- After program finishes, it generates a denoised Z-stack from the trained model. You might need to run `Image › Adjust › Brightness/Contrast...` and hit `Reset` to adjust the display of the denoised image.\n- The Deep Learning model you just trained could be saved as a .ZIP file (to be used for prediction in the future) by clicking on the `File actions > Save to...`\n  \n  ![Saving deep learning model](PNGs/N2V_saving_model.png)\n- Trained model could also be applied immediately on a single noisy image or a folder full of noisy images by using `Predict > Single image or stack` or `Predict > Folder of images of stacks`, respectively.  \n  \n  ![Applying deep learning model](PNGs/N2V_running_current_model.png)\n\n","srcMarkdownNoYaml":"\n\n::: {layout-nrow=1 layout-ncol=2}\n![Original](PNGs/fish4_celegans_dyn-10_ceff-90_final.ics.ome_Z45.png)\n\n![After processing with trained Noise2Void model](PNGs/fish4_celegans_dyn-10_ceff-90_final.ics.ome_n2v_Z45.png)\n:::\n\nSpinning disk confocal image of FISH in C. elegans (image courtesy of [ABRF/LMRG Image Analysis Study](https://sites.google.com/view/lmrg-image-analysis-study)).  \n\n[Download TIF file](images/fish4_celegans.tif)  \n  \n- Open the above Z-stack in Fiji and run the command: \n  `Plugins › CSBDeep › N2V › N2V train + predict`  \n- You will be presented with a `N2V train + predict` window. Choose the following options and click OK.\n  - Axes of prediction input: XYZ\n  - Number of epochs: 10\n  - Number of steps per epoch: 10\n  - Batch size per step: 64\n  - Patch shape: 64\n  - Neighborhood readius: 5\n\n- A window showing the progress of different steps (Preparation, Training and Prediction) will open. As the training progresses, training loss (red) and validation loss (blue) curves are displayed in the window (see below). If training goes well, then both the red and blue curves will decrease with more cycles (epochs) of training and stabilize around a minimum loss value (~ 1.0 in the image below). Training loss goes down from the beginning but Validation loss (blue curve) usually goes up in the beginning and then comes down and approaches the red curve.\n\n  ![Training deep learning model](PNGs/N2V_training_progress.png)\n \n  If by the end of the training, red and blue curves do not stabilize to a minimum loss value, then increase the number of epochs to 20 or 30 and then run the command `N2V train + predict` again.\n- After program finishes, it generates a denoised Z-stack from the trained model. You might need to run `Image › Adjust › Brightness/Contrast...` and hit `Reset` to adjust the display of the denoised image.\n- The Deep Learning model you just trained could be saved as a .ZIP file (to be used for prediction in the future) by clicking on the `File actions > Save to...`\n  \n  ![Saving deep learning model](PNGs/N2V_saving_model.png)\n- Trained model could also be applied immediately on a single noisy image or a folder full of noisy images by using `Predict > Single image or stack` or `Predict > Folder of images of stacks`, respectively.  \n  \n  ![Applying deep learning model](PNGs/N2V_running_current_model.png)\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":false,"output-file":"Image_analysis_workshop_2022_Exercise3.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.26","editor":{"render-on-save":true},"theme":{"light":"flatly","dark":"darkly"},"fig-cap-location":"bottom","title":"Exercise 3 - Denoising using deep learning method (Noise2Void)"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}